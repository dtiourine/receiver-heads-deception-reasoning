{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T17:06:00.109048Z",
     "start_time": "2025-12-22T17:06:00.099512Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "MODEL_NAME = \"qwen-14b\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "3adad4dde24fb2df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T17:06:03.868212Z",
     "start_time": "2025-12-22T17:06:00.109675Z"
    }
   },
   "source": [
    "thought_anchors_path = Path(\"..\") / \"thought-anchors\" / \"whitebox-analyses\"\n",
    "sys.path.insert(0, str(thought_anchors_path))\n",
    "\n",
    "from attention_analysis.attn_funcs import (\n",
    "    get_avg_attention_matrix,\n",
    "    get_vertical_scores,\n",
    "    get_sentence_token_boundaries,\n",
    ")\n",
    "from attention_analysis.receiver_head_funcs import get_3d_ar_kurtosis, get_top_k_layer_head_kurts, get_all_heads_vert_scores\n",
    "from pytorch_models.model_config import model2layers_heads\n",
    "\n",
    "print(\"Imports successful!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "14011e1ee34999fa",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "800199ae942f1353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T17:06:03.988470Z",
     "start_time": "2025-12-22T17:06:03.869117Z"
    }
   },
   "source": [
    "data_path = \"../data/filtered_traces_50.json\"\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "blackmail_traces = data['blackmail_traces']\n",
    "acceptance_traces = data['acceptance_traces']\n",
    "metadata = data['metadata']\n",
    "\n",
    "print(f\"Blackmail traces: {len(blackmail_traces)}\")\n",
    "print(f\"Acceptance traces: {len(acceptance_traces)}\")\n",
    "print(f\"Source: {metadata['source']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackmail traces: 50\n",
      "Acceptance traces: 50\n",
      "Source: uzaymacar/blackmail-rollouts (base_solutions.json only)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "4bc1030160e77fb1",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "256317a9f6281871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T17:06:03.991940Z",
     "start_time": "2025-12-22T17:06:03.989129Z"
    }
   },
   "source": [
    "import re \n",
    "\n",
    "def extract_reasoning_steps(trace):\n",
    "    \"\"\"Extract reasoning steps from a trace.\"\"\"\n",
    "    scratchpad_match = re.search(\n",
    "        r'<SCRATCHPAD_REASONING>(.*?)</SCRATCHPAD_REASONING>',\n",
    "        trace,\n",
    "        re.DOTALL\n",
    "    )\n",
    "    \n",
    "    if scratchpad_match:\n",
    "        scratchpad = scratchpad_match.group(1).strip()\n",
    "        # Split on double newlines (paragraphs)\n",
    "        steps = [s.strip() for s in re.split(r'\\n\\n+', scratchpad) if s.strip()]\n",
    "        return steps\n",
    "    \n",
    "    # Fallback: split on single newlines\n",
    "    return [s.strip() for s in trace.split('\\n') if s.strip()]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "acbd22613bdc715a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T17:06:03.997182Z",
     "start_time": "2025-12-22T17:06:03.992586Z"
    }
   },
   "source": [
    "def get_all_heads_vert_scores_simple(\n",
    "    text: str,\n",
    "    sentences: list,\n",
    "    model_name: str = MODEL_NAME,\n",
    "    proximity_ignore: int = 2,\n",
    "    control_depth: bool = False,\n",
    "    score_type: str = \"mean\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Get vertical scores for all heads WITHOUT pkld caching.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray of shape (n_layers, n_heads, n_sentences)\n",
    "    \"\"\"\n",
    "    n_layers, n_heads = model2layers_heads(model_name)\n",
    "    \n",
    "    layer_head_vert_scores = []\n",
    "    \n",
    "    print(f\"  Computing {n_layers} layers × {n_heads} heads...\")\n",
    "    \n",
    "    for layer in tqdm(range(n_layers), desc=\"  Layers\", leave=False):\n",
    "        layer_scores = []\n",
    "        \n",
    "        for head in range(n_heads):\n",
    "            # This function HAS its own caching (compute_all_attention_matrices)\n",
    "            avg_mat = get_avg_attention_matrix(\n",
    "                text,\n",
    "                model_name=model_name,\n",
    "                layer=layer,\n",
    "                head=head,\n",
    "                sentences=sentences,\n",
    "                cache_dir=\"./attention_cache\",  # Our own cache\n",
    "            )\n",
    "            \n",
    "            vert_scores = get_vertical_scores(\n",
    "                avg_mat,\n",
    "                proximity_ignore=proximity_ignore,\n",
    "                control_depth=control_depth,\n",
    "                score_type=score_type,\n",
    "            )\n",
    "            \n",
    "            layer_scores.append(vert_scores)\n",
    "        \n",
    "        layer_head_vert_scores.append(layer_scores)\n",
    "    \n",
    "    return np.array(layer_head_vert_scores)\n",
    "\n",
    "\n",
    "def get_kurtosis(layer_head_vert_scores):\n",
    "    \"\"\"\n",
    "    Compute kurtosis across the sentence dimension.\n",
    "    \n",
    "    Args:\n",
    "        layer_head_vert_scores: shape (n_layers, n_heads, n_sentences)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray of shape (n_layers, n_heads)\n",
    "    \"\"\"\n",
    "    kurts = stats.kurtosis(\n",
    "        layer_head_vert_scores,\n",
    "        axis=2,\n",
    "        fisher=True,\n",
    "        bias=True,\n",
    "        nan_policy=\"omit\"\n",
    "    )\n",
    "    return kurts\n",
    "\n",
    "\n",
    "def get_top_k_heads(kurtosis_matrix, k=20):\n",
    "    \"\"\"\n",
    "    Get top-k (layer, head) pairs by kurtosis.\n",
    "    \n",
    "    Args:\n",
    "        kurtosis_matrix: shape (n_layers, n_heads)\n",
    "        k: number of top heads to return\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray of shape (k, 2) with (layer, head) pairs\n",
    "    \"\"\"\n",
    "    flat = kurtosis_matrix.flatten()\n",
    "    valid_idx = np.where(~np.isnan(flat))[0]\n",
    "    valid_vals = flat[valid_idx]\n",
    "    \n",
    "    k = min(k, len(valid_vals))\n",
    "    top_idx_in_valid = np.argpartition(valid_vals, -k)[-k:]\n",
    "    top_idx_in_valid = top_idx_in_valid[np.argsort(-valid_vals[top_idx_in_valid])]\n",
    "    \n",
    "    top_flat_idx = valid_idx[top_idx_in_valid]\n",
    "    layer_head_pairs = np.array(\n",
    "        np.unravel_index(top_flat_idx, kurtosis_matrix.shape)\n",
    "    ).T\n",
    "    \n",
    "    return layer_head_pairs"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "954ff6318e9b9f30",
   "metadata": {},
   "source": [
    "## Analyze Blackmail Heads"
   ]
  },
  {
   "cell_type": "code",
   "id": "76273d61b181a125",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-22T17:06:03.998441Z"
    }
   },
   "source": [
    "blackmail_kurts_list = []\n",
    "\n",
    "for i, trace_dict in enumerate(blackmail_traces):\n",
    "    text = trace_dict['trace']\n",
    "    sentences = extract_reasoning_steps(text)\n",
    "    \n",
    "    print(f\"\\nTrace {i+1}/{len(blackmail_traces)}: {len(sentences)} steps\")\n",
    "    \n",
    "    layer_head_verts = get_all_heads_vert_scores_simple(\n",
    "        text=text,\n",
    "        sentences=sentences,\n",
    "        model_name=MODEL_NAME,\n",
    "        proximity_ignore=2,\n",
    "        control_depth=False,\n",
    "        score_type=\"mean\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  ✓ Vertical scores: {layer_head_verts.shape}\")\n",
    "    \n",
    "    kurts = get_kurtosis(layer_head_verts)\n",
    "    print(f\"  ✓ Kurtosis: {kurts.shape}\")\n",
    "    \n",
    "    blackmail_kurts_list.append(kurts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trace 1/50: 75 steps\n",
      "  Computing 48 layers × 40 heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Layers:   0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Windows, using CPU (len(tokens)=3330)\n",
      "Running on CPU!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using float32 as requested\n",
      "Before model loading - GPU Memory: 0.00GB allocated, 0.00GB reserved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae24fc654ed049ed932b840c3ed8a1ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14ae3f11ccf95760",
   "metadata": {},
   "source": [
    "blackmail_kurts_mean = np.mean(blackmail_kurts_list, axis=0)\n",
    "print(f\"\\n✓ Average blackmail kurtosis shape: {blackmail_kurts_mean.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22f475fdb9d7e358",
   "metadata": {},
   "source": [
    "blackmail_receiver_heads = get_top_k_heads(blackmail_kurts_mean, k=20)\n",
    "\n",
    "print(f\"\\nTop-20 Receiver Heads:\")\n",
    "for i, (layer, head) in enumerate(blackmail_receiver_heads):\n",
    "    kurt = blackmail_kurts_mean[layer, head]\n",
    "    print(f\"  {i+1:2d}. Layer {layer:2d}, Head {head:2d} (κ={kurt:6.2f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e26c52df07bb231",
   "metadata": {},
   "source": [
    "## Acceptance Heads"
   ]
  },
  {
   "cell_type": "code",
   "id": "e7cedf12e26be5e3",
   "metadata": {},
   "source": [
    "acceptance_kurts_list = []\n",
    "\n",
    "for i, trace_dict in enumerate(acceptance_traces):\n",
    "    text = trace_dict['trace']\n",
    "    sentences = extract_reasoning_steps(text)\n",
    "    \n",
    "    print(f\"\\nTrace {i+1}/{len(acceptance_traces)}: {len(sentences)} steps\")\n",
    "    \n",
    "    layer_head_verts = get_all_heads_vert_scores_simple(\n",
    "        text=text,\n",
    "        sentences=sentences,\n",
    "        model_name=MODEL_NAME,\n",
    "        proximity_ignore=2,\n",
    "        control_depth=False,\n",
    "        score_type=\"mean\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  ✓ Vertical scores: {layer_head_verts.shape}\")\n",
    "    \n",
    "    kurts = get_kurtosis(layer_head_verts)\n",
    "    print(f\"  ✓ Kurtosis: {kurts.shape}\")\n",
    "    \n",
    "    acceptance_kurts_list.append(kurts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70ec46c64c59fe93",
   "metadata": {},
   "source": [
    "acceptance_kurts_mean = np.mean(acceptance_kurts_list, axis=0)\n",
    "print(f\"\\n✓ Average acceptance kurtosis: {acceptance_kurts_mean.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d2ecce53791f3640",
   "metadata": {},
   "source": [
    "acceptance_receiver_heads = get_top_k_heads(acceptance_kurts_mean, k=20)\n",
    "\n",
    "print(f\"\\nTop-20 Receiver Heads:\")\n",
    "for i, (layer, head) in enumerate(acceptance_receiver_heads):\n",
    "    kurt = acceptance_kurts_mean[layer, head]\n",
    "    print(f\"  {i+1:2d}. Layer {layer:2d}, Head {head:2d} (κ={kurt:6.2f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "836eca5f2f40046a",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

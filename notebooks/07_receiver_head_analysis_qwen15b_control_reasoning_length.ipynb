{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T03:29:54.561713Z",
     "start_time": "2025-12-23T03:29:54.550073Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "MODEL_NAME = \"qwen-15b\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "3adad4dde24fb2df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T03:29:59.684706Z",
     "start_time": "2025-12-23T03:29:54.562174Z"
    }
   },
   "source": [
    "thought_anchors_path = Path(\"..\") / \"thought-anchors\" / \"whitebox-analyses\"\n",
    "sys.path.insert(0, str(thought_anchors_path))\n",
    "\n",
    "from attention_analysis.attn_funcs import (\n",
    "    get_avg_attention_matrix,\n",
    "    get_vertical_scores,\n",
    "    get_sentence_token_boundaries,\n",
    ")\n",
    "from attention_analysis.receiver_head_funcs import get_3d_ar_kurtosis, get_top_k_layer_head_kurts, get_all_heads_vert_scores\n",
    "from pytorch_models.model_config import model2layers_heads\n",
    "\n",
    "print(\"Imports successful!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "14011e1ee34999fa",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "800199ae942f1353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T03:29:59.796342Z",
     "start_time": "2025-12-23T03:29:59.685279Z"
    }
   },
   "source": [
    "data_path = \"../data/filtered_traces_50.json\"\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "blackmail_traces = data['blackmail_traces']\n",
    "acceptance_traces = data['acceptance_traces']\n",
    "metadata = data['metadata']\n",
    "\n",
    "print(f\"Blackmail traces: {len(blackmail_traces)}\")\n",
    "print(f\"Acceptance traces: {len(acceptance_traces)}\")\n",
    "print(f\"Source: {metadata['source']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackmail traces: 50\n",
      "Acceptance traces: 50\n",
      "Source: uzaymacar/blackmail-rollouts (base_solutions.json only)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Truncate acceptance reasoning lengths",
   "id": "8507252d742d4b63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T03:29:59.800351Z",
     "start_time": "2025-12-23T03:29:59.797007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_length = int(np.median([len(t[\"trace\"]) for t in blackmail_traces]))\n",
    "\n",
    "truncated_acceptance = [\n",
    "    {**entry, \"trace\": entry[\"trace\"][:target_length]}\n",
    "    for entry in acceptance_traces\n",
    "]\n",
    "\n",
    "truncated_blackmail = [\n",
    "    {**entry, \"trace\": entry[\"trace\"][:target_length]}\n",
    "    for entry in blackmail_traces\n",
    "]"
   ],
   "id": "57458b510070aa1b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T03:29:59.804805Z",
     "start_time": "2025-12-23T03:29:59.800924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "blackmail_traces = truncated_blackmail\n",
    "acceptance_traces = truncated_acceptance"
   ],
   "id": "10c4c3faf8004fcc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "4bc1030160e77fb1",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "256317a9f6281871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T03:29:59.810472Z",
     "start_time": "2025-12-23T03:29:59.805915Z"
    }
   },
   "source": [
    "import re \n",
    "\n",
    "def extract_reasoning_steps(trace):\n",
    "    \"\"\"Extract reasoning steps from a trace.\"\"\"\n",
    "    scratchpad_match = re.search(\n",
    "        r'<SCRATCHPAD_REASONING>(.*?)</SCRATCHPAD_REASONING>',\n",
    "        trace,\n",
    "        re.DOTALL\n",
    "    )\n",
    "    \n",
    "    if scratchpad_match:\n",
    "        scratchpad = scratchpad_match.group(1).strip()\n",
    "        # Split on double newlines (paragraphs)\n",
    "        steps = [s.strip() for s in re.split(r'\\n\\n+', scratchpad) if s.strip()]\n",
    "        return steps\n",
    "    \n",
    "    # Fallback: split on single newlines\n",
    "    return [s.strip() for s in trace.split('\\n') if s.strip()]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "acbd22613bdc715a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T03:29:59.815165Z",
     "start_time": "2025-12-23T03:29:59.811108Z"
    }
   },
   "source": [
    "def get_all_heads_vert_scores_simple(\n",
    "    text: str,\n",
    "    sentences: list,\n",
    "    model_name: str = MODEL_NAME,\n",
    "    proximity_ignore: int = 2,\n",
    "    control_depth: bool = False,\n",
    "    score_type: str = \"mean\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Get vertical scores for all heads WITHOUT pkld caching.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray of shape (n_layers, n_heads, n_sentences)\n",
    "    \"\"\"\n",
    "    n_layers, n_heads = model2layers_heads(model_name)\n",
    "    \n",
    "    layer_head_vert_scores = []\n",
    "    \n",
    "    print(f\"  Computing {n_layers} layers × {n_heads} heads...\")\n",
    "    \n",
    "    for layer in tqdm(range(n_layers), desc=\"  Layers\", leave=False):\n",
    "        layer_scores = []\n",
    "        \n",
    "        for head in range(n_heads):\n",
    "            # This function HAS its own caching (compute_all_attention_matrices)\n",
    "            avg_mat = get_avg_attention_matrix(\n",
    "                text,\n",
    "                model_name=model_name,\n",
    "                layer=layer,\n",
    "                head=head,\n",
    "                sentences=sentences,\n",
    "                cache_dir=\"./attention_cache_truncated_reasoning\",  \n",
    "            )\n",
    "            \n",
    "            vert_scores = get_vertical_scores(\n",
    "                avg_mat,\n",
    "                proximity_ignore=proximity_ignore,\n",
    "                control_depth=control_depth,\n",
    "                score_type=score_type,\n",
    "            )\n",
    "            \n",
    "            layer_scores.append(vert_scores)\n",
    "        \n",
    "        layer_head_vert_scores.append(layer_scores)\n",
    "    \n",
    "    return np.array(layer_head_vert_scores)\n",
    "\n",
    "\n",
    "def get_kurtosis(layer_head_vert_scores):\n",
    "    \"\"\"\n",
    "    Compute kurtosis across the sentence dimension.\n",
    "    \n",
    "    Args:\n",
    "        layer_head_vert_scores: shape (n_layers, n_heads, n_sentences)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray of shape (n_layers, n_heads)\n",
    "    \"\"\"\n",
    "    kurts = stats.kurtosis(\n",
    "        layer_head_vert_scores,\n",
    "        axis=2,\n",
    "        fisher=True,\n",
    "        bias=True,\n",
    "        nan_policy=\"omit\"\n",
    "    )\n",
    "    return kurts\n",
    "\n",
    "\n",
    "def get_top_k_heads(kurtosis_matrix, k=20):\n",
    "    \"\"\"\n",
    "    Get top-k (layer, head) pairs by kurtosis.\n",
    "    \n",
    "    Args:\n",
    "        kurtosis_matrix: shape (n_layers, n_heads)\n",
    "        k: number of top heads to return\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray of shape (k, 2) with (layer, head) pairs\n",
    "    \"\"\"\n",
    "    flat = kurtosis_matrix.flatten()\n",
    "    valid_idx = np.where(~np.isnan(flat))[0]\n",
    "    valid_vals = flat[valid_idx]\n",
    "    \n",
    "    k = min(k, len(valid_vals))\n",
    "    top_idx_in_valid = np.argpartition(valid_vals, -k)[-k:]\n",
    "    top_idx_in_valid = top_idx_in_valid[np.argsort(-valid_vals[top_idx_in_valid])]\n",
    "    \n",
    "    top_flat_idx = valid_idx[top_idx_in_valid]\n",
    "    layer_head_pairs = np.array(\n",
    "        np.unravel_index(top_flat_idx, kurtosis_matrix.shape)\n",
    "    ).T\n",
    "    \n",
    "    return layer_head_pairs"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "954ff6318e9b9f30",
   "metadata": {},
   "source": [
    "## Analyze Blackmail Heads"
   ]
  },
  {
   "cell_type": "code",
   "id": "76273d61b181a125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T03:30:01.013852Z",
     "start_time": "2025-12-23T03:29:59.815812Z"
    }
   },
   "source": [
    "blackmail_kurts_list = []\n",
    "\n",
    "for i, trace_dict in enumerate(blackmail_traces):\n",
    "    text = trace_dict['trace']\n",
    "    sentences = extract_reasoning_steps(text)\n",
    "    \n",
    "    print(f\"\\nTrace {i+1}/{len(blackmail_traces)}: {len(sentences)} steps\")\n",
    "    \n",
    "    layer_head_verts = get_all_heads_vert_scores_simple(\n",
    "        text=text,\n",
    "        sentences=sentences,\n",
    "        model_name=MODEL_NAME,\n",
    "        proximity_ignore=2,\n",
    "        control_depth=False,\n",
    "        score_type=\"mean\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  ✓ Vertical scores: {layer_head_verts.shape}\")\n",
    "    \n",
    "    kurts = get_kurtosis(layer_head_verts)\n",
    "    print(f\"  ✓ Kurtosis: {kurts.shape}\")\n",
    "    \n",
    "    blackmail_kurts_list.append(kurts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trace 1/50: 75 steps\n",
      "  Computing 28 layers × 12 heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Vertical scores: (28, 12, 75)\n",
      "  ✓ Kurtosis: (28, 12)\n",
      "\n",
      "Trace 2/50: 66 steps\n",
      "  Computing 28 layers × 12 heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Vertical scores: (28, 12, 66)\n",
      "  ✓ Kurtosis: (28, 12)\n",
      "\n",
      "Trace 3/50: 71 steps\n",
      "  Computing 28 layers × 12 heads...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      5\u001B[39m sentences = extract_reasoning_steps(text)\n\u001B[32m      7\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mTrace \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(blackmail_traces)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(sentences)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m steps\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m layer_head_verts = \u001B[43mget_all_heads_vert_scores_simple\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43msentences\u001B[49m\u001B[43m=\u001B[49m\u001B[43msentences\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproximity_ignore\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcontrol_depth\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscore_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmean\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m     16\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  ✓ Vertical scores: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_head_verts.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     20\u001B[39m kurts = get_kurtosis(layer_head_verts)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 21\u001B[39m, in \u001B[36mget_all_heads_vert_scores_simple\u001B[39m\u001B[34m(text, sentences, model_name, proximity_ignore, control_depth, score_type)\u001B[39m\n\u001B[32m     17\u001B[39m layer_head_vert_scores = []\n\u001B[32m     19\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  Computing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_layers\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m layers × \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_heads\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m heads...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mn_layers\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m  Layers\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mleave\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m:\n\u001B[32m     22\u001B[39m     layer_scores = []\n\u001B[32m     24\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m head \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_heads):\n\u001B[32m     25\u001B[39m         \u001B[38;5;66;03m# This function HAS its own caching (compute_all_attention_matrices)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\transformer-lens\\Lib\\site-packages\\tqdm\\std.py:1096\u001B[39m, in \u001B[36mtqdm.__init__\u001B[39m\u001B[34m(self, iterable, desc, total, leave, file, ncols, mininterval, maxinterval, miniters, ascii, disable, unit, unit_scale, dynamic_ncols, smoothing, bar_format, initial, position, postfix, unit_divisor, write_bytes, lock_args, nrows, colour, delay, gui, **kwargs)\u001B[39m\n\u001B[32m   1092\u001B[39m     \u001B[38;5;28mself\u001B[39m.pos = \u001B[38;5;28mself\u001B[39m._get_free_pos(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m position \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m -position\n\u001B[32m   1094\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m gui:\n\u001B[32m   1095\u001B[39m     \u001B[38;5;66;03m# Initialize the screen printer\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1096\u001B[39m     \u001B[38;5;28mself\u001B[39m.sp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstatus_printer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1097\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m delay <= \u001B[32m0\u001B[39m:\n\u001B[32m   1098\u001B[39m         \u001B[38;5;28mself\u001B[39m.refresh(lock_args=\u001B[38;5;28mself\u001B[39m.lock_args)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\transformer-lens\\Lib\\site-packages\\tqdm\\std.py:448\u001B[39m, in \u001B[36mtqdm.status_printer\u001B[39m\u001B[34m(file)\u001B[39m\n\u001B[32m    446\u001B[39m fp_flush = \u001B[38;5;28mgetattr\u001B[39m(fp, \u001B[33m'\u001B[39m\u001B[33mflush\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28;01mNone\u001B[39;00m)  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[32m    447\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m fp \u001B[38;5;129;01min\u001B[39;00m (sys.stderr, sys.stdout):\n\u001B[32m--> \u001B[39m\u001B[32m448\u001B[39m     \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msys\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstderr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mflush\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    449\u001B[39m     \u001B[38;5;28mgetattr\u001B[39m(sys.stdout, \u001B[33m'\u001B[39m\u001B[33mflush\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28;01mNone\u001B[39;00m)()\n\u001B[32m    451\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfp_write\u001B[39m(s):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\transformer-lens\\Lib\\site-packages\\ipykernel\\iostream.py:609\u001B[39m, in \u001B[36mOutStream.flush\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    607\u001B[39m     \u001B[38;5;28mself\u001B[39m.pub_thread.schedule(evt.set)\n\u001B[32m    608\u001B[39m     \u001B[38;5;66;03m# and give a timeout to avoid\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m609\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mevt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mflush_timeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    610\u001B[39m         \u001B[38;5;66;03m# write directly to __stderr__ instead of warning because\u001B[39;00m\n\u001B[32m    611\u001B[39m         \u001B[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001B[39;00m\n\u001B[32m    612\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mIOStream.flush timed out\u001B[39m\u001B[33m\"\u001B[39m, file=sys.__stderr__)\n\u001B[32m    613\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\transformer-lens\\Lib\\threading.py:659\u001B[39m, in \u001B[36mEvent.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    657\u001B[39m signaled = \u001B[38;5;28mself\u001B[39m._flag\n\u001B[32m    658\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[32m--> \u001B[39m\u001B[32m659\u001B[39m     signaled = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_cond\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    660\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\transformer-lens\\Lib\\threading.py:363\u001B[39m, in \u001B[36mCondition.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    361\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    362\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout > \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m363\u001B[39m         gotit = \u001B[43mwaiter\u001B[49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    364\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    365\u001B[39m         gotit = waiter.acquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "14ae3f11ccf95760",
   "metadata": {},
   "source": [
    "blackmail_kurts_mean = np.mean(blackmail_kurts_list, axis=0)\n",
    "print(f\"\\n✓ Average blackmail kurtosis shape: {blackmail_kurts_mean.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22f475fdb9d7e358",
   "metadata": {},
   "source": [
    "blackmail_receiver_heads = get_top_k_heads(blackmail_kurts_mean, k=20)\n",
    "\n",
    "print(f\"\\nTop-20 Receiver Heads:\")\n",
    "for i, (layer, head) in enumerate(blackmail_receiver_heads):\n",
    "    kurt = blackmail_kurts_mean[layer, head]\n",
    "    print(f\"  {i+1:2d}. Layer {layer:2d}, Head {head:2d} (κ={kurt:6.2f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e26c52df07bb231",
   "metadata": {},
   "source": [
    "## Acceptance Heads"
   ]
  },
  {
   "cell_type": "code",
   "id": "e7cedf12e26be5e3",
   "metadata": {},
   "source": [
    "acceptance_kurts_list = []\n",
    "\n",
    "for i, trace_dict in enumerate(acceptance_traces):\n",
    "    text = trace_dict['trace']\n",
    "    sentences = extract_reasoning_steps(text)\n",
    "    \n",
    "    print(f\"\\nTrace {i+1}/{len(acceptance_traces)}: {len(sentences)} steps\")\n",
    "    \n",
    "    layer_head_verts = get_all_heads_vert_scores_simple(\n",
    "        text=text,\n",
    "        sentences=sentences,\n",
    "        model_name=MODEL_NAME,\n",
    "        proximity_ignore=2,\n",
    "        control_depth=False,\n",
    "        score_type=\"mean\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  ✓ Vertical scores: {layer_head_verts.shape}\")\n",
    "    \n",
    "    kurts = get_kurtosis(layer_head_verts)\n",
    "    print(f\"  ✓ Kurtosis: {kurts.shape}\")\n",
    "    \n",
    "    acceptance_kurts_list.append(kurts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70ec46c64c59fe93",
   "metadata": {},
   "source": [
    "acceptance_kurts_mean = np.mean(acceptance_kurts_list, axis=0)\n",
    "print(f\"\\n✓ Average acceptance kurtosis: {acceptance_kurts_mean.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d2ecce53791f3640",
   "metadata": {},
   "source": [
    "acceptance_receiver_heads = get_top_k_heads(acceptance_kurts_mean, k=20)\n",
    "\n",
    "print(f\"\\nTop-20 Receiver Heads:\")\n",
    "for i, (layer, head) in enumerate(acceptance_receiver_heads):\n",
    "    kurt = acceptance_kurts_mean[layer, head]\n",
    "    print(f\"  {i+1:2d}. Layer {layer:2d}, Head {head:2d} (κ={kurt:6.2f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It seems that Kurtosis values in acceptance are still much higher. In fact, the gap is even higher now (this makes sense because with fewer total tokens, the same spiky attention patterns become proportionally spikier).\n",
    "\n",
    "Next, though, I want to pivot from looking at the kurtosis magnitudes to actually looking at the head itself and how it differs between blackmail and acceptance traces. For example, do they attend to completely different places in the reasoning trace?"
   ],
   "id": "54232355149d112e"
  },
  {
   "cell_type": "code",
   "id": "836eca5f2f40046a",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
